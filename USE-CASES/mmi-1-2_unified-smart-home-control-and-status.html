<h1 id="mmi-1-2_unified-smart-home-control-and-status">Title: Unified Smart Home Control and Status Interface</h1>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-submitter">Submitter(s):</h2>

Michael McCool

<h2 id="mmi-1-2_unified-smart-home-control-and-status-reviewer">Reviewer(s):</h2>

<Suggest reviewers>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-tracker issue id">Tracker Issue ID:</h2>

<please leave blank>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-category">Category:</h2>

Accessibility

<h2 id="mmi-1-2_unified-smart-home-control-and-status-class">Class:</h2>

<please leave blank>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-status">Status:</h2>

<please leave blank>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-target users">Target Users:</h2>

&lt;List all users that are involved in the use case, e.g. device manufacturer, gateway manufacturer, cloud provider&gt;

<h2 id="mmi-1-2_unified-smart-home-control-and-status-motivation">Motivation:</h2>

The increase in the number of controllable devices in an
intelligent home creates a problem with controlling all available services
in a coherent and useful manner.
Having a shared context,
built from information collected through sensors and direct user input,
 would improve recognition of user intent, and thus simplify interactions.
<br><br>
In addition,
multiple input mechanisms could be selected by the user based on device type,
level of trust and the type of interaction required for a particular task.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-expected devices">Expected Devices:</h2>

Mobile phone or other client running an application providing command
mediation capabilities.
<br><br>
IoT-enabled smart home devices supporting
remote sensing and actuation functionality.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-expected data">Expected Data:</h2>

Command and status information transferred between the command mediation
application and one or more devices.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-dependencies">Dependencies:</h2>

<ul>
<li>WoT Thing Description</li>
<li>WoT Discovery</li>
<li>Optional: WoT Scripting API accessible from application for interacting
  with devices.</li>
</ul>

<h2 id="mmi-1-2_unified-smart-home-control-and-status-description">Description:</h2>

Smart home functionality (window blinds, lights, air conditioning etc.)
is controlled through a multimodal interface,
composed from modalities built into the house itself
(e.g. speech and gesture recognition)
and those available on the user's personal devices
(e.g. smartphone touchscreen).
The system may automatically adapt to the preferences of a specific user,
or enter a more complex interaction if multiple people are present.
<br><br>
Sensors built into various devices around the house can act as input
modalities that feed information to the home and affect its behavior.
For example,
lights and temperature in the gym room can be adapted dynamically
as workout intensity recorded by the fitness equipment increases.
The same data can also increase or decrease volume and tempo of music tracks
played by the user's mobile device or the home's media system.

<h3 id="mmi-1-2_unified-smart-home-control-and-status-variants">Variants:</h3>

The intelligent home in tandem with the user's personal
devices can additionally monitor user behavior for emotional patterns
such as 'tired' or 'busy' and adapt further.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-gaps">Gaps:</h2>

A service may be needed to recognize gestures and emotional states.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-existing standards">Existing standards:</h2>

This use case is based on MMI UC 1.2; original title was Intelligent Home Apparatus.

<h2 id="mmi-1-2_unified-smart-home-control-and-status-comments">Comments:</h2>

Does not include Requirements section from original MMI use case.
